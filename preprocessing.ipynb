{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nyKPeRNkIA1g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel('/content/dataset.xlsx')\n"
      ],
      "metadata": {
        "id": "i8SNh-y8JIXr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9VE3R_HJcbj",
        "outputId": "bd443bed-f962-442d-f1ae-c905aee0196f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_with_zeros = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
        "df[cols_with_zeros] = df[cols_with_zeros].replace(0, np.nan)\n",
        "#NaN clearly tells Python/ML libraries “this is missing”.\n",
        "#Libraries like scikit-learn can handle NaN using imputers (SimpleImputer, KNNImputer etc.).\n",
        "#If you keep 0 as is, your model will think patients can actually have Glucose=0, which adds noise and hurts accuracy."
      ],
      "metadata": {
        "id": "QHXqyEqWJql-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Imputation Strategies\n",
        "\n",
        "mean→ fill missing values with column mean\n",
        "\n",
        "median → fill missing values with column median (robust against outliers 👍)\n",
        "\n",
        "most_frequent → fill with mode (common for categorical data)\n",
        "\n",
        "constant → replace with a fixed value you set"
      ],
      "metadata": {
        "id": "2L2Op2oGKuR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean is sensitive → one extreme value can distort it a lot.\n",
        "\n",
        "The median is robust → it only cares about the order of values, not how far they are.\n"
      ],
      "metadata": {
        "id": "x6ZLJjMRLRHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Median is robust because it ignores extremes.\n",
        "#Use mean only if the distribution is roughly normal.\n",
        "#Use mode for categorical features.\n",
        "\n",
        "# Step 1: Create the imputer (median strategy)\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "# Step 2: Fit on the dataset (calculate medians for each column)\n",
        "imputer.fit(df[cols_with_zeros])\n",
        "\n",
        "# You can check what medians were learned\n",
        "print(\"Calculated medians:\", imputer.statistics_)\n",
        "\n",
        "# Step 3: Transform (replace NaN with those medians)\n",
        "df[cols_with_zeros] = imputer.transform(df[cols_with_zeros])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUvegs9RNcHE",
        "outputId": "838968b8-c0ba-486f-d807-048d34719c84"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated medians: [117.   72.   29.  125.   32.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the imputer\n",
        "with open(\"imputer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(imputer, f)\n"
      ],
      "metadata": {
        "id": "eQsTSOjyWKjQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('preprocessed_dataset_without_scaling.csv', index=False)"
      ],
      "metadata": {
        "id": "BrEN1pjXIujm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_capped=df.copy()\n",
        "\n",
        "for col in df_capped.columns[:-1]: #exclude target column\n",
        "  col_mean=df_capped[col].mean()\n",
        "  col_std=df_capped[col].std()\n",
        "  upper_limit=col_mean+(3*col_std)\n",
        "  lower_limit=col_mean-(3*col_std)\n",
        "  df_capped[col]=np.where(df_capped[col]>upper_limit,upper_limit,df_capped[col])\n",
        "  df_capped[col]=np.where(df_capped[col]<lower_limit,lower_limit,df_capped[col])\n",
        "  #np.where(condition, value_if_true, value_if_false)\n",
        "  #for i in range(len(df_capped)):\n",
        "    # if df_capped.loc[i,col]>upper_limit:\n",
        "    # df_capped.loc[i,col]=upper_limit\n",
        "    # elf df_capped.loc[i,col]<lower_limit:\n",
        "    # df_capped.loc[i,col]=lower_limit"
      ],
      "metadata": {
        "id": "sm60uE_S7W9o"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_capped.to_csv('outlier_refined.csv',index=False)"
      ],
      "metadata": {
        "id": "84cQRt-DKwfH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df_capped.drop(\"Outcome\", axis=1)\n",
        "#input features\n",
        "y=df_capped[\"Outcome\"]\n",
        "#output features"
      ],
      "metadata": {
        "id": "QrdWnpPVOqv8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "RwY767A6QmM1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(stratify=y): Ensures that the proportion of each class in train and test is the same as in the original dataset.\n",
        "#This is not eliminating randomness, it’s still random within each class. So your model still sees varied samples, but the classes are fairly represented.\n",
        "#Scaling means changing the range of your features so that they are on a similar scale.\n",
        "# This is important because many machine learning algorithms (like logistic regression, SVM, KNN, neural networks, etc.) are sensitive to the magnitude of input features.\n",
        "#z=(x-mean)/standard_deviation\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "qLKtPK7xSZA-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
        "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGhN0YS6We3E",
        "outputId": "d7baec1b-7219-4c17-af6c-1a7368b96502"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_scaled shape: (614, 8)\n",
            "X_test_scaled shape: (154, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU8BpeuTZjAQ",
        "outputId": "73fea69d-fad3-4afc-e7be-8546c8269bbf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
            "       'BMI', 'DiabetesPedigreeFunction', 'Age'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled_df=pd.DataFrame(X_train_scaled,columns=X.columns)\n",
        "X_test_scaled_df=pd.DataFrame(X_test_scaled,columns=X.columns)\n"
      ],
      "metadata": {
        "id": "7RICiqlEZm3x"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training features\n",
        "X_train_scaled_df.to_csv(\"X_train_scaled.csv\", index=False)"
      ],
      "metadata": {
        "id": "KuY9BPaZDVgI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save testing features\n",
        "X_test_scaled_df.to_csv(\"X_test_scaled.csv\", index=False)"
      ],
      "metadata": {
        "id": "ZzYmtnqwDftZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save labels (targets)\n",
        "y_train.to_csv(\"y_train.csv\", index=False)\n",
        "y_test.to_csv(\"y_test.csv\", index=False)"
      ],
      "metadata": {
        "id": "lsCZotnKDttU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "idUIuhEuG4ws"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#By dumping (saving) it into a file called scaler.pkl\n",
        "#you can later load the exact same scaler when making predictions.\n",
        "with open(\"scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler, f)"
      ],
      "metadata": {
        "id": "PuLB_DABG7Lk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This saves the list of column names used during training\n",
        "with open(\"feature_columns.pkl\", \"wb\") as f:\n",
        "    pickle.dump(X.columns.tolist(), f)"
      ],
      "metadata": {
        "id": "hZSrGafxHBsn"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}